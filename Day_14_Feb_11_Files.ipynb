{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20dd474-314e-46c7-97d1-967e717d3ca0",
   "metadata": {},
   "source": [
    "# Working with files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb25c1e1-da5b-4bfd-91c4-ac48ed3d16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open file in write mode \n",
    "# syntax - open(\"file_name\", mode)\n",
    "# mode 'w' is used to open file in write mode. It opens the existing file or creates new if it does not exist.\n",
    "# whenver mode 'w' is used it'll remove the previous content of file (truncate) and add new content\n",
    "# mode 'a' is used to keep previous data and the new data will be appended into that file.\n",
    "\n",
    "f = open(\"test.text\", 'w') # creates a file in present working directory if it does not exist or opens the existing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81365f3b-d32c-466b-8125-ef7f969e781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd  # to check present working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d93d7f-26fb-4859-9e43-ef037c9c7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment_1_Jan_29.ipynb       Day_3_Jan_31.ipynb\n",
      "Assignment_2_Jan_30.ipynb       Day_4_Feb_1.ipynb\n",
      "Assignment_3_Feb_2.ipynb        Day_5_Feb_2_dict.ipynb\n",
      "Assignment_4_Feb_3.ipynb        Day_5_Feb_2_Sets.ipynb\n",
      "Assignment_5_Feb_4.ipynb        Day_5_Feb_2_tuples.ipynb\n",
      "Assignment_6_Feb_5.ipynb        Day_6_Feb_3_Functions.ipynb\n",
      "Assignment_7_Feb_6.ipynb        Day_7_Feb_4_Function_2.ipynb\n",
      "Assignment_8_Feb_7.ipynb        Day_8_Feb_5_OOPs_1.ipynb\n",
      "Assignment_9_Feb_9.ipynb        In_Class_Practice.ipynb\n",
      "Day_11_Feb_8_OOPs_2.ipynb       README.md\n",
      "Day_13_Feb_10_Decorators.ipynb  sample-code.ipynb\n",
      "Day_14_Feb_11_Files.ipynb       test.text\n",
      "Day_1_Jan_29.ipynb              Tips.ipynb\n",
      "Day_2_Jan_30.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls     # shows all the file inside present working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa91d9b6-c3ca-4306-96dd-689f0ceb19ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to write inside the file\n",
    "\n",
    "f.write(\"this is my first write operation inside the file\") \n",
    "\n",
    "# the write operation will not close the file\n",
    "# until you close the file the write operation will not get reflected inside the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac729c1-8b11-497b-b242-0e91cf7baed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to close the file \n",
    "# only after closing the file the data entered in the write operation will get reflected inside the file\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48911489-c978-4633-ab6a-8d9f9995c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.text\", 'w')\n",
    "f.write(\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\")\n",
    "f.close()\n",
    "\n",
    "# this write operation will remove all the data exist in the file and add new data to it (truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d269189b-8ac9-46f8-b4fe-cfdf0f3475c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.text\", 'a')\n",
    "f.write(\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\")\n",
    "f.close()\n",
    "\n",
    "# this write operation will keep all the data exist in the file and append new data to it (append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fd07b88-b914-47fd-9938-1facf32e6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open file in read mode\n",
    "\n",
    "data = open(\"test.text\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a55d75f6-120d-4cce-9235-6c422628c36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.read() # to read the contents/data of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e986301b-17a5-4bc7-affd-81f92f5e9dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.read()\n",
    "\n",
    "# Again usind data.read() will give blank result.\n",
    "# reason is the cursor is set at very end of the file because after that there is no data\n",
    "# to reset cursor, use data.seek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6875f38-7b91-4e92-ab93-5ac113b4f531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to reset cursor, use data.seek()\n",
    "\n",
    "data.seek(0) # this will reset the cursor at zeroth (starting) position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16569c0e-b5b2-4363-bf36-a0f83e6a27bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23c0d9f4-b055-49b5-ad3b-e3f0cf444b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.seek(100) # this will reset the cursor at hundredth (100th) position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "739b8cd9-e251-41cf-bcbe-03ce87879621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fb91cd7-ff01-4acf-b8c3-c461d45264ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to read data\n",
    "\n",
    "data1 = open(\"test.text\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5f8390c-feaa-4723-af9f-a0d482d413f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\n"
     ]
    }
   ],
   "source": [
    "# Alternative way to read data\n",
    "\n",
    "for i in data1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40e1ccb4-5c65-4b8f-be3b-70be3a6b79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1438"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know the file size\n",
    "\n",
    "import os  # importing os module which is already available inside python\n",
    "os.path.getsize(\"test.text\") # this fill give the file size in byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32afc09c-9b7b-412d-ba40-1c9bd004352d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_test.text'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create a copy of the file\n",
    "\n",
    "import shutil\n",
    "shutil.copy(\"test.text\", \"new_test.text\")\n",
    "\n",
    "# syntax - shutil.copy(\"old_file_name\", \"new_file_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff791de5-51cc-4bac-94cc-8867815a9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete the file\n",
    "\n",
    "os.remove(\"test.text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef46501e-7015-49a5-ab9b-abaf079e9f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects.\n"
     ]
    }
   ],
   "source": [
    "# alternate file to open a file\n",
    "\n",
    "with open(\"new_test.text\", 'r') as f:    # f is alias\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c297d51-87ae-401e-9059-1328c78398af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rename a file\n",
    "\n",
    "os.rename(\"new_test.text\", \"test1.txt\")  # syntax - os.rename(\"old file name\", \"new file name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4ea10-304d-43ee-88b2-cd0e1a077b2d",
   "metadata": {},
   "source": [
    "## Read and write with diff.-diff. file system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47fe0b-e381-4b46-a40b-8cc56cae2755",
   "metadata": {},
   "source": [
    "* Java Script Object Notation (json)\n",
    "> * File format which is been used massively and widely used across industry in terms of transferring data from one application to another appliocation\n",
    "> * json store data in key and value pair. So in python dictionary is equivalent to json file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63a1422e-3130-4433-bf22-dd9df264c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\" : \"hello\",\n",
    "    \"maild_id\" : \"hello@gmail.com\",\n",
    "    \"phone_number\" : 588797646,\n",
    "    \"subject\" : [\"data science\", \"big data\", \"data analytics\"]\n",
    "}\n",
    "\n",
    "# json store data in key and value pair. So in python dictionary is equivalent to json file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55866bbc-661d-4479-9f09-8585bba897c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to store above dict data as json file format?\n",
    "\n",
    "import json\n",
    "with open(\"test1.json\", 'w') as f:\n",
    "    json.dump(data, f)                 # to write use .dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af5fd6b8-0753-4a19-9f3b-ecd83ac43b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"test1.json\", 'r') as f:\n",
    "    test1 = json.load(f)               # to read use .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b46500be-adae-4b16-8bfa-f6c70fd5f033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'hello',\n",
       " 'maild_id': 'hello@gmail.com',\n",
       " 'phone_number': 588797646,\n",
       " 'subject': ['data science', 'big data', 'data analytics']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ad44fbc-f322-48b9-bc7b-6e0c4d04dd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'big data'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract 'big data'\n",
    "test1['subject'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae6f3d-e1dc-44f3-9f85-66d944c1e9a4",
   "metadata": {},
   "source": [
    "### Read and write operation for For *comma separated data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53756d32-3a06-4268-98e9-cbfcb5df72ac",
   "metadata": {},
   "source": [
    "#### To store in .csv (comma separated value) file format\n",
    "\n",
    "* Condition - the data must be separated by comma(,) to perform read and write in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a5d4f63-5f38-45a2-a13c-29d26230c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\"name\", \"email_id\", \"number\"],\n",
    "    [\"sudh\", \"sudh@gmail.com\", 6499565463],\n",
    "    [\"krish\", \"krish@gmail.com\", 5685487545]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "909576d7-fa3a-4f1b-b75b-882207afc2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to store above data as .csv file format?\n",
    "\n",
    "import csv\n",
    "with open(\"test3.csv\", 'w') as f:\n",
    "    w = csv.writer(f)    # creating object to write\n",
    "    for i in data:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "316c0dd9-49bc-47c6-a21f-b5b255614fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'email_id', 'number']\n",
      "['sudh', 'sudh@gmail.com', '6499565463']\n",
      "['krish', 'krish@gmail.com', '5685487545']\n"
     ]
    }
   ],
   "source": [
    "# How to read data from .csv file format?\n",
    "\n",
    "import csv\n",
    "with open(\"test3.csv\", 'r') as f:\n",
    "    read = csv.reader(f)\n",
    "    for i in read:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df98344-e85f-49b3-90b6-674c3539e27b",
   "metadata": {},
   "source": [
    "### Read and write operation for *binary data*\n",
    "\n",
    "* .bin is the extension for binary files\n",
    "* used to store image, audio, video kind of data\n",
    "* binary file store data in 0 & 1 code which is not understandable by humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ebdc71d-0891-427c-a4a0-3c82ac152b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to write data in .bin file format?\n",
    "\n",
    "with open(\"test4.bin\" , 'wb') as f :  # 'wb' mode is write binary\n",
    "    f.write(b\"\\x01\\x02\\x03\")    # b means binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd5c5578-2a67-4d6a-ac5f-bad409d4dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x02\\x03'\n"
     ]
    }
   ],
   "source": [
    "# How to read data from .bin file format?\n",
    "\n",
    "with open(\"test4.bin\", 'rb') as f :  # 'rb' is read binary\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1306d56-f951-434b-8684-f641d2453b22",
   "metadata": {},
   "source": [
    "## Buffered Read and Write Operation\n",
    "\n",
    "* When the file size is very large (in GBs and TBs) we still need to do read and write operation.\n",
    "* For that we use buffer read and write which will read and write file in small small chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0a49e0-5e3d-422a-ba4b-373be322a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eae8530-65b8-45b2-84ac-e7c8b83b0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"wb\") as f:\n",
    "    file = io.BufferedWriter(f)\n",
    "    file.write(b\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. \\n\")\n",
    "    file.write(b\"this is my second line that i am trying to write\")\n",
    "    file.flush()  # used to close file\n",
    "    \n",
    "# With buffer write we can achieve data write in chunks\n",
    "# by default this function is going to write all of the data/information in bits and pieces or in samll samll chunks\n",
    "# chunk size is by default set as 8192 bytes and can be modified to other size as well\n",
    "# that means 8192 byte of data it can write inside file in one go or one chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad11392-1c16-4f3e-b9ef-6fcae7228e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. \\nthis is my second line that i am trying to write\"\n"
     ]
    }
   ],
   "source": [
    "# buffer reading\n",
    "\n",
    "with open(\"test.txt\" , \"rb\") as f:\n",
    "    file = io.BufferedReader(f)\n",
    "    data = file.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94c1fc0-342e-4348-b9ce-ea46353f65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Data Scien'\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\" , \"rb\") as f:\n",
    "    file = io.BufferedReader(f)\n",
    "    data = file.read(10) # can read only 10 bytes of data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9199436e-7550-45ed-b30e-3e3ea8b1ffdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Data Science Masters course is highly curated and uniquely designed according to the latest industry'\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\" , \"rb\") as f:\n",
    "    file = io.BufferedReader(f)\n",
    "    data = file.read(100) # can read only 100 bytes of data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335cf50a-dd1f-4aa9-83ac-365265fc5db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. \\nthis is my second line that i am trying to write\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\" , \"rb\") as f:\n",
    "    file = io.BufferedReader(f)\n",
    "    data = file.read(1000) # can read only 1000 bytes of data\n",
    "    print(data)\n",
    "    \n",
    "# in this way the chunk size can be defined to read data in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84bd94-a6ad-4a65-a6ec-2d219228e602",
   "metadata": {},
   "source": [
    "# Logging & Debugger\n",
    "\n",
    "* whenever an error or bug arises at any point of time in any code or program then just priniting it or geting those output in console it is not going to fulfill the objective\n",
    "* because wherever error or bug arises it needs to be attented by looking into it\n",
    "* Hence, logging concept comes into the picture\n",
    "* In general, in production grade code you are not supposed to use print() because print() will always print something inside console and once machine is shutdown everything is gone.\n",
    "* So some permanent storage is required where log of each and everything is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d349b57-c787-4cfd-adc9-30425780307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7074ddbc-771f-43ba-80c2-29b7f39c880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = \"test.log\" , level = logging.INFO) # Setting label is INFO\n",
    "\n",
    "# instead of printing on console, logging file is used to keep all the inforamtion as a log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38970d6e-a67a-4e21-bce1-0c68cd1c3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"this is my line of execution\")\n",
    "\n",
    "# here info log label is used beacuse i am logging things as information\n",
    "# but there are other log label as well like error, debug, critical, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b252b00c-b12c-4467-b120-9e0af653b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.error(\"this is my error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f70f47-487f-4309-be6c-74ece984a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.critical(\"this is my critical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d2f7e-cd21-4509-8a8c-951404ff8b9f",
   "metadata": {},
   "source": [
    "* Logging Hierarchy\n",
    "\n",
    "1. NOSET\n",
    "2. DEBUG\n",
    "3. INFO\n",
    "4. WARNING\n",
    "5. ERROR\n",
    "6. CRITICAL\n",
    "\n",
    "in above code we are setting label as INFO, so all the labels below info (WARNING, ERROR, CRITICAL) can be logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da7f5db-1689-4778-a210-deb060970985",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"this is my warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baee9c59-f7b3-49f2-a821-2837e610886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"this is my info related to debug\")\n",
    "\n",
    "# Nothing will be logged w.r.t tag as DEBUG\n",
    "# the reason being the lable is set to INFO\n",
    "# so whatever comes below info can be logged\n",
    "# whatever comes above info cannot be logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1657aef2-28df-4780-9b29-79179885ee0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'logging' has no attribute 'noset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is my noset related log\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# depricated from latest python version. In earlier python version it was available.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'logging' has no attribute 'noset'"
     ]
    }
   ],
   "source": [
    "logging.noset(\"this is my noset related log\") # depricated from latest python version. In earlier python version it was available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "962cf05d-64d0-4566-ac4d-cf2a59314e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to stop logging\n",
    "\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e96739e-04f4-4e09-929f-574f8023f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG lable\n",
    "\n",
    "logging.basicConfig(filename = \"test1.log\" , level = logging.DEBUG , format = '%(asctime)s %(message)s')\n",
    "\n",
    "# foramt is used to log timestamp with message\n",
    "# format is just setting the placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06600dc-30b0-45cc-9087-0479ea6445aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"this is my debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11501f77-e515-45df-a07e-c3ad3acd5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"this is my info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e96f997-09ee-4504-bd70-5ed76c9ddaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"this is my warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b366b9-ca8c-473a-85c8-5e3b6bf5e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a642fcf-cdc7-4267-bd28-f50d35efcf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = \"test3.log\", level = logging.DEBUG, format = '%(asctime)s %(name)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99348945-0a7b-4963-8239-3de0efb58da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"this is my info log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d050fa8-d41f-455b-aa6f-b333ec41463f",
   "metadata": {},
   "source": [
    "#### using logging in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8ad2d9-291e-4b84-8344-25c4f3d21d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,[4,5,6], \"hello\", \"world\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63dc7f05-95fe-4d91-ab72-b814b80ba804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one list with integers and other with strings\n",
    "\n",
    "l1_int = []\n",
    "l2_str = []\n",
    "for i in l:\n",
    "    logging.info(\"this is the start of my first for loop {}\".format(l))\n",
    "    logging.info(\"this is the value of i that i am logging {}\".format(i))\n",
    "    if type(i) == list:\n",
    "        for j in i:\n",
    "            logging.info(\"logging in my j {j} and i {i}\".format(j = j, i = i))\n",
    "            if type(j) == int:\n",
    "                l1_int.append(j)\n",
    "    elif type(i) == int:\n",
    "        l1_int.append(i)\n",
    "    else:\n",
    "        if type(i) == str:\n",
    "            l2_str.append(i)\n",
    "logging.info(\"this is my final result with all int {l1}, and with all str {l2}\".format(l1 = l1_int, l2 = l2_str))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670ed402-11ad-4fbb-a70f-9938198c2686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 4, 5, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ae44b6-32bd-4831-b4dd-84442cde6cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46b45c-d038-416a-8358-a71e5ec50681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
